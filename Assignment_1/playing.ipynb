{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive function for determinant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determ(A):\n",
    "    \n",
    "    A = np.array(A)\n",
    "    \n",
    "    assert (len(A.shape) == 2), \"Input matrix must be a 2D matrix: is {}D\".format(len(A.shape))\n",
    "    assert (A.shape[0] == A.shape[1]), \"Input matrix must be a square matrix: has {} rows and {} columns\".format(A.shape[0],A.shape[1])\n",
    "    \n",
    "    if A.shape == (1,1):\n",
    "        return A[0,0]\n",
    "    \n",
    "    else: \n",
    "        result = 0\n",
    "        for i in np.arange(A.shape[0]):\n",
    "            result += ((-1) ** i)*A[i, 0]*determ(np.delete(np.delete(A, i, 0), 0, 1))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7\n",
      "0\n",
      "1368\n"
     ]
    }
   ],
   "source": [
    "a=np.array([[1,3],[3,2]])\n",
    "print(determ(a))\n",
    "\n",
    "a = np.array([[1,1,1],[2,2,2],[3,3,3]])\n",
    "print(determ(a))\n",
    "\n",
    "a = np.array([[1,2,3,4,5],[4,7,3,2,1],[5,7,0,1,3],[3,4,6,1,3],[0,4,7,1,2]])\n",
    "print(determ(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Stuff because I am an e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73105858 0.88079708 0.95257413]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7310585786300049, 0.8807970779778823, 0.9525741268224334]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(1/(1+np.exp(-np.array([1,2,3]))))\n",
    "\n",
    "import math\n",
    "[1/(1+math.exp(-y)) for y in np.array([1,2,3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0.]\n",
      "[ 41  37  22 289  49]\n",
      "37\n",
      "[1.97227962e-108 3.61235614e-110 1.10502813e-116 1.00000000e+000\n",
      " 5.87928270e-105]\n",
      "[[1]\n",
      " [2]\n",
      " [3]]\n",
      "[[1.97227962e-108 3.61235614e-110 1.10502813e-116 1.00000000e+000\n",
      "  5.87928270e-105]\n",
      " [3.94455925e-108 7.22471228e-110 2.21005625e-116 2.00000000e+000\n",
      "  1.17585654e-104]\n",
      " [5.91683887e-108 1.08370684e-109 3.31508438e-116 3.00000000e+000\n",
      "  1.76378481e-104]]\n",
      "abc\n",
      "[3.61235614e-110]\n",
      "[[-1.]\n",
      " [-2.]\n",
      " [-3.]]\n"
     ]
    }
   ],
   "source": [
    "# 5 words, 3 embeddings\n",
    "U = np.array([[1,2,3,4,5],[5,4,2,6,7],[10,9,5,91,10]])\n",
    "v_c = np.array([1,2,3])\n",
    "outsideWordIdx = 1\n",
    "\n",
    "y = np.zeros(U.shape[1])\n",
    "y[outsideWordIdx] = 1\n",
    "print(y)\n",
    "\n",
    "# Compute 'y hat'\n",
    "u_o = U[:, outsideWordIdx]\n",
    "denominator = np.sum((U.T * v_c), axis=1)\n",
    "print(denominator)\n",
    "numerator = denominator[outsideWordIdx]\n",
    "print(numerator)\n",
    "y_hat = softmax(denominator)\n",
    "\n",
    "#print(denominator)\n",
    "print(y_hat)\n",
    "\n",
    "y_hat.shape = (5, 1)\n",
    "v_c.shape = (3, 1)\n",
    "print(v_c)\n",
    "\n",
    "print(v_c * y_hat.T)\n",
    "print('abc')\n",
    "\n",
    "print(y_hat[outsideWordIdx])\n",
    "print(y_hat[outsideWordIdx] * v_c - v_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9722796241351285e-108\n",
      "3.6123561383267394e-110\n",
      "1.105028125193164e-116\n",
      "1.0\n",
      "5.8792826982452694e-105\n"
     ]
    }
   ],
   "source": [
    "print(np.exp(41)/(np.exp(41)+np.exp(37)+np.exp(22)+np.exp(289)+np.exp(49)))\n",
    "print(np.exp(37)/(np.exp(41)+np.exp(37)+np.exp(22)+np.exp(289)+np.exp(49)))\n",
    "print(np.exp(22)/(np.exp(41)+np.exp(37)+np.exp(22)+np.exp(289)+np.exp(49)))\n",
    "print(np.exp(289)/(np.exp(41)+np.exp(37)+np.exp(22)+np.exp(289)+np.exp(49)))\n",
    "print(np.exp(49)/(np.exp(41)+np.exp(37)+np.exp(22)+np.exp(289)+np.exp(49)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   2   3   4   5]\n",
      " [ 10   8   4  12  14]\n",
      " [ 30  27  15 273  30]]\n",
      "[ 41  37  22 289  49]\n",
      "[ 15  48 375]\n"
     ]
    }
   ],
   "source": [
    "print((U.T * v_c).T)\n",
    "print(np.sum((U.T * v_c).T, axis=0))\n",
    "print(np.sum((U.T * v_c).T, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outsideWordIdx = 1\n",
    "\n",
    "y = np.zeros(U.shape[1])\n",
    "y[outsideWordIdx] = 1\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.        , -0.69314718, -1.09861229, -1.38629436, -1.60943791],\n",
       "       [-2.30258509, -2.07944154, -1.38629436, -2.48490665, -2.63905733],\n",
       "       [-3.40119738, -3.29583687, -2.7080502 , -5.6094718 , -3.40119738]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log((U.T * v_c).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.zeros(U.shape[1])\n",
    "y[1] = 1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 2., 0., 0., 0.],\n",
       "       [0., 4., 0., 0., 0.],\n",
       "       [0., 9., 0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04201007, 0.84379473, 0.1141952 ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute the softmax function for each row of the input x.\n",
    "    It is crucial that this function is optimized for speed because\n",
    "    it will be used frequently in later code. \n",
    "\n",
    "    Arguments:\n",
    "    x -- A D dimensional vector or N x D dimensional numpy matrix.\n",
    "    Return:\n",
    "    x -- You are allowed to modify x in-place\n",
    "    \"\"\"\n",
    "    orig_shape = x.shape\n",
    "\n",
    "    if len(x.shape) > 1:\n",
    "        # Matrix\n",
    "        tmp = np.max(x, axis=1)\n",
    "        x -= tmp.reshape((x.shape[0], 1))\n",
    "        x = np.exp(x)\n",
    "        tmp = np.sum(x, axis=1)\n",
    "        x /= tmp.reshape((x.shape[0], 1))\n",
    "    else:\n",
    "        # Vector\n",
    "        tmp = np.max(x)\n",
    "        x -= tmp\n",
    "        x = np.exp(x)\n",
    "        tmp = np.sum(x)\n",
    "        x /= tmp\n",
    "\n",
    "    assert x.shape == orig_shape\n",
    "    return x\n",
    "\n",
    "softmax(np.array([1,4,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1535649948951077"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
